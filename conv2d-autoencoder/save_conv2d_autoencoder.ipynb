{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do what the keras people suggest\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('demo_style.mplstyle')\n",
    "\n",
    "#tf.keras.backend.clear_session()  # For easy reset of notebook state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'771048'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get job info\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"SLURM_JOB_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q003_data = np.load('/global/cscratch1/sd/stephey/march2020_data/Output/q003_data.npy')\n",
    "#q003_max = np.load('/global/cscratch1/sd/stephey/march2020_data/Output/q003_max.npy')\n",
    "#q003_norm = np.load('/global/cscratch1/sd/stephey/march2020_data/Output/q003_norm.npy')\n",
    "\n",
    "q103_data = np.load('/global/cscratch1/sd/stephey/march2020_data/Output2/q103_data.npy') \n",
    "#q103_max = np.load('/global/cscratch1/sd/stephey/march2020_data/Output2/q103_max.npy')\n",
    "#q103_norm = np.load('/global/cscratch1/sd/stephey/march2020_data/Output2/q103_norm.npy')\n",
    "\n",
    "#add in our post-quench data\n",
    "#need to cut that down to size, too\n",
    "\n",
    "pq_data = np.load('/global/cscratch1/sd/stephey/march2020_data/Q3_Q103_postquench/pq_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut to make square for later autoencoder friendly size\n",
    "\n",
    "q003_data = q003_data[:,0:512,:]\n",
    "q103_data = q103_data[:,0:512,:]\n",
    "pq_data = pq_data[:,0:512,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9807, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#we shuffle in the training so it's ok\n",
    "qall_data = np.concatenate((q003_data, q103_data, pq_data), axis=0)\n",
    "\n",
    "print(qall_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, Activation, MaxPool2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten, Reshape, Conv2DTranspose, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 512, 512, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 256, 32)      1600      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      50208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 16)        25104     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        12560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 8)         6280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 8)         32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 8)           3144      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 8)           32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 8)           3144      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 8)           32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "latent (Dense)               (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, None, None, 8)     3144      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, None, None, 8)     32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, None, None, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, None, None, 8)     3144      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, None, None, 8)     32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, None, None, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, None, None, 4)     1572      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, None, None, 4)     16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, None, None, 4)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, None, None, 4)     788       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, None, None, 4)     16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, None, None, 4)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, None, None, 2)     394       \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, None, None, 2)     8         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, None, None, 2)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, None, None, 2)     198       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, None, None, 2)     8         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, None, None, 2)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, None, None, 1)     19        \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, None, None, 1)     4         \n",
      "_________________________________________________________________\n",
      "outputs (Activation)         (None, None, None, 1)     0         \n",
      "=================================================================\n",
      "Total params: 114,079\n",
      "Trainable params: 113,781\n",
      "Non-trainable params: 298\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "autoencoder = tf.keras.models.load_model('conv2d_autoencoder')\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "#this seems either buggy or we've done something wrong\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 512, 512, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 256, 256, 32)      1600      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256, 256, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      50208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 16)        25104     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 16)        12560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 8)         6280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 8)         32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 8)           3144      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 8)           32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 8, 8, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 4, 4, 8)           3144      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4, 4, 8)           32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 4, 4, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "latent (Dense)               (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 103,552\n",
      "Trainable params: 103,312\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = tf.keras.Model(inputs=autoencoder.inputs, outputs=autoencoder.get_layer('latent').output)\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all our data into the encoder\n",
    "\n",
    "qall_reshape = np.expand_dims(qall_data, -1)\n",
    "encoded_all = encoder.predict(qall_reshape)\n",
    "\n",
    "np.save('encoded_all', encoded_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
